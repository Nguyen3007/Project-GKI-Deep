{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRsR0oLabP9U",
        "outputId": "2f976841-3ff9-4d68-fa88-78d3e8cb9b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã giải nén IIIT 5K-word.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Nếu bạn tải file zip, giải nén như sau:\n",
        "zip_path = \"/content/IIIT5K.zip\"\n",
        "extract_path = \"/content/IIIT5K\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "print(\"Đã giải nén IIIT 5K-word.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import os\n",
        "\n",
        "def mat_to_labeltxt(mat_path, save_txt):\n",
        "    mat = scipy.io.loadmat(mat_path)\n",
        "    # Tên biến struct trong file là traindata hoặc testdata\n",
        "    # Lấy đúng key, bỏ các key __header__, __version__, __globals__\n",
        "    keys = [k for k in mat.keys() if not k.startswith(\"__\")]\n",
        "    struct_key = keys[0]\n",
        "    struct = mat[struct_key][0]  # là mảng các sample struct\n",
        "\n",
        "    with open(save_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "        for entry in struct:\n",
        "            img_name = str(entry[\"ImgName\"][0])\n",
        "            gt = str(entry[\"GroundTruth\"][0])\n",
        "            # img_name đã chứa \"train/xxx.png\" hoặc \"test/xxx.png\"\n",
        "            img_path = os.path.join(\"/content/IIIT5K/IIIT5K\", img_name)\n",
        "            # Nếu ảnh tồn tại thì ghi ra label\n",
        "            if os.path.exists(img_path):\n",
        "                f.write(f\"{img_name} {gt}\\n\")\n",
        "    print(f\"Saved {save_txt}\")\n",
        "\n",
        "train_mat = \"/content/IIIT5K/IIIT5K/traindata.mat\"\n",
        "test_mat = \"/content/IIIT5K/IIIT5K/testdata.mat\"\n",
        "\n",
        "train_labeltxt = \"/content/IIIT5K/IIIT5K/train_label.txt\"\n",
        "test_labeltxt = \"/content/IIIT5K/IIIT5K/test_label.txt\"\n",
        "\n",
        "mat_to_labeltxt(train_mat, train_labeltxt)\n",
        "mat_to_labeltxt(test_mat, test_labeltxt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJqEaWOegYZr",
        "outputId": "73ebe652-534f-44f0-8d57-ae3fe3ad4cff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/IIIT5K/IIIT5K/train_label.txt\n",
            "Saved /content/IIIT5K/IIIT5K/test_label.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_characters_iiit5k(label_file):\n",
        "    charset = set()\n",
        "    with open(label_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split(' ', 1)\n",
        "            if len(parts) < 2:\n",
        "                continue\n",
        "            word = parts[1]\n",
        "            for ch in word:\n",
        "                charset.add(ch)\n",
        "    return charset\n",
        "\n",
        "def write_vocab_iiit5k(charset, save_path='/content/IIIT5K/IIIT5K/vocab.txt'):\n",
        "    tokens = ['<PAD>', '<BOS>', '<EOS>', '<UNK>']\n",
        "    charset = sorted(list(charset))\n",
        "    with open(save_path, 'w', encoding='utf-8') as f:\n",
        "        for token in tokens:\n",
        "            f.write(token + '\\n')\n",
        "        for ch in charset:\n",
        "            f.write(ch + '\\n')\n",
        "    print(f'Vocab saved to {save_path}. Total chars (not count special tokens): {len(charset)}')\n",
        "\n",
        "label_file = \"/content/IIIT5K/IIIT5K/train_label.txt\"\n",
        "charset = collect_characters_iiit5k(label_file)\n",
        "write_vocab_iiit5k(charset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCf7LVYvjGMw",
        "outputId": "9133bba5-c201-4c2a-899e-4575f2fa03f5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab saved to /content/IIIT5K/IIIT5K/vocab.txt. Total chars (not count special tokens): 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab:\n",
        "    def __init__(self, vocab_path):\n",
        "        self.idx2char = []\n",
        "        with open(vocab_path, encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                self.idx2char.append(line.strip('\\n'))\n",
        "        self.char2idx = {ch: idx for idx, ch in enumerate(self.idx2char)}\n",
        "        self.pad_idx = self.char2idx['<PAD>']\n",
        "        self.bos_idx = self.char2idx['<BOS>']\n",
        "        self.eos_idx = self.char2idx['<EOS>']\n",
        "        self.unk_idx = self.char2idx['<UNK>']\n",
        "\n",
        "    def encode(self, text, max_length):\n",
        "        ids = [self.bos_idx]\n",
        "        for ch in text:\n",
        "            ids.append(self.char2idx.get(ch, self.unk_idx))\n",
        "        ids.append(self.eos_idx)\n",
        "        ids = ids[:max_length]\n",
        "        ids += [self.pad_idx] * (max_length - len(ids))\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids):\n",
        "        chars = []\n",
        "        for idx in ids:\n",
        "            ch = self.idx2char[idx]\n",
        "            if ch in ['<PAD>', '<BOS>', '<EOS>']:\n",
        "                continue\n",
        "            chars.append(ch)\n",
        "        return ''.join(chars)"
      ],
      "metadata": {
        "id": "Z4ufejwljWCs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "class IIIT5KWordDataset(Dataset):\n",
        "    def __init__(self, label_file, vocab_path, max_label_length=32, img_height=32, img_width=100, transform=None):\n",
        "        self.vocab = Vocab(vocab_path)\n",
        "        self.max_label_length = max_label_length\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        self.transform = transform or transforms.Compose([\n",
        "            transforms.Resize((img_height, img_width)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "        self.samples = []\n",
        "        with open(label_file, encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split(' ', 1)\n",
        "                if len(parts) < 2:\n",
        "                    continue\n",
        "                img_name, text = parts[0], parts[1]\n",
        "                # Fix: Use os.path.join to correctly construct the path\n",
        "                img_path = os.path.join(\"/content/IIIT5K/IIIT5K\", img_name)\n",
        "                if os.path.exists(img_path):\n",
        "                    self.samples.append((img_path, text))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, text = self.samples[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img = self.transform(img)\n",
        "        label_ids = self.vocab.encode(text, self.max_label_length)\n",
        "        label_ids = torch.tensor(label_ids, dtype=torch.long)\n",
        "        return img, label_ids, text"
      ],
      "metadata": {
        "id": "SnsNTrQajXFe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_file = \"/content/IIIT5K/IIIT5K/train_label.txt\"\n",
        "vocab_path = \"/content/IIIT5K/IIIT5K/vocab.txt\"\n",
        "max_label_length = 32\n",
        "img_height, img_width = 32, 100\n",
        "\n",
        "dataset = IIIT5KWordDataset(label_file, vocab_path, max_label_length, img_height, img_width)\n",
        "print(\"Samples:\", len(dataset))\n",
        "img, label_ids, text = dataset[0]\n",
        "print(\"Image shape:\", img.shape)\n",
        "print(\"Label ids:\", label_ids)\n",
        "print(\"Decoded:\", dataset.vocab.decode(label_ids.tolist()))\n",
        "print(\"Groundtruth text:\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coVotijtjnep",
        "outputId": "bd15e0e5-e8e8-47b5-ebd7-5ebbac2beead"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples: 2000\n",
            "Image shape: torch.Size([3, 32, 100])\n",
            "Label ids: tensor([ 1, 38, 28, 34,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
            "Decoded: YOU\n",
            "Groundtruth text: YOU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class CNNBackbone(nn.Module):\n",
        "    def __init__(self, out_channels=256):\n",
        "        super().__init__()\n",
        "        resnet = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "        self.conv_layers = nn.Sequential(*list(resnet.children())[:-2])\n",
        "        self.proj = nn.Conv2d(resnet.fc.in_features, out_channels, 1)\n",
        "    def forward(self, x):\n",
        "        feat = self.conv_layers(x)\n",
        "        feat = self.proj(feat)\n",
        "        return feat\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=256):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-torch.log(torch.tensor(10000.0))/d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1), :]\n",
        "\n",
        "class OCRTransformerDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=256, nhead=4, num_layers=3, dropout=0.1, max_len=32):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.token_embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_embed = PositionalEncoding(d_model, max_len)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, d_model*2, dropout)\n",
        "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
        "        self.output_proj = nn.Linear(d_model, vocab_size)\n",
        "    def forward(self, memory, tgt, tgt_mask=None):\n",
        "        tgt_emb = self.token_embed(tgt) * (self.d_model ** 0.5)\n",
        "        tgt_emb = self.pos_embed(tgt_emb)\n",
        "        tgt_emb = tgt_emb.transpose(0,1)\n",
        "        memory = memory.transpose(0,1)\n",
        "        output = self.transformer_decoder(tgt_emb, memory, tgt_mask=tgt_mask)\n",
        "        output = output.transpose(0,1)\n",
        "        logits = self.output_proj(output)\n",
        "        return logits\n",
        "\n",
        "class OCRNet(nn.Module):\n",
        "    def __init__(self, vocab_size, max_seq_len=32, d_model=256):\n",
        "        super().__init__()\n",
        "        self.cnn = CNNBackbone(out_channels=d_model)\n",
        "        self.feat2seq = nn.Linear(d_model, d_model)\n",
        "        self.decoder = OCRTransformerDecoder(vocab_size, d_model, nhead=4, num_layers=3, max_len=max_seq_len)\n",
        "    def forward(self, images, tgt_input, tgt_mask=None):\n",
        "        feat = self.cnn(images)\n",
        "        B, C, H, W = feat.shape\n",
        "        feat = feat.permute(0,2,3,1).contiguous().view(B, H*W, C)\n",
        "        feat = self.feat2seq(feat)\n",
        "        logits = self.decoder(feat, tgt_input, tgt_mask)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "r_3TOx7OkGdB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ocr_loss_fn(logits, labels, pad_idx):\n",
        "    logits = logits.reshape(-1, logits.size(-1))\n",
        "    labels = labels.reshape(-1)\n",
        "    loss = nn.CrossEntropyLoss(ignore_index=pad_idx)(logits, labels)\n",
        "    return loss\n",
        "\n",
        "def create_tgt_mask(tgt_input, pad_idx):\n",
        "    B, tgt_len = tgt_input.shape\n",
        "    tgt_mask = torch.triu(torch.ones((tgt_len, tgt_len)), diagonal=1).bool().to(tgt_input.device)\n",
        "    return tgt_mask"
      ],
      "metadata": {
        "id": "mHtJlWCjkHnp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, device, pad_idx):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels, _ in dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        tgt_input = labels[:, :-1]\n",
        "        tgt_out = labels[:, 1:]\n",
        "        tgt_mask = create_tgt_mask(tgt_input, pad_idx)\n",
        "        logits = model(images, tgt_input, tgt_mask)\n",
        "        loss = ocr_loss_fn(logits, tgt_out, pad_idx)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, dataloader, device, pad_idx):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    total_count = 0\n",
        "    for images, labels, _ in dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        tgt_input = labels[:, :-1]\n",
        "        tgt_out = labels[:, 1:]\n",
        "        tgt_mask = create_tgt_mask(tgt_input, pad_idx)\n",
        "        logits = model(images, tgt_input, tgt_mask)\n",
        "        loss = ocr_loss_fn(logits, tgt_out, pad_idx)\n",
        "        total_loss += loss.item()\n",
        "        preds = logits.argmax(dim=-1)\n",
        "        mask = (tgt_out != pad_idx)\n",
        "        acc = ((preds == tgt_out) & mask).sum().item() / mask.sum().item()\n",
        "        total_acc += acc\n",
        "        total_count += 1\n",
        "    return total_loss / total_count, total_acc / total_count\n",
        "\n",
        "pad_idx = dataset.vocab.pad_idx\n",
        "batch_size = 64\n",
        "num_epochs = 30\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "vocab_size = len(dataset.vocab.idx2char)\n",
        "max_seq_len = max_label_length\n",
        "\n",
        "model = OCRNet(vocab_size=vocab_size, max_seq_len=max_seq_len).to(device)\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_one_epoch(model, train_loader, optimizer, device, pad_idx)\n",
        "    print(f\"Epoch {epoch+1} | Train loss: {train_loss:.4f}\")\n",
        "    # Nếu có val_loader:\n",
        "    # val_loss, val_acc = evaluate(model, val_loader, device, pad_idx)\n",
        "    # print(f\"Val loss: {val_loss:.4f} | Val acc: {val_acc:.4f}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"/content/ocr_cnn_transformer_iiit5k.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAhgsCSmkJRm",
        "outputId": "df303aa1-79a2-47e9-8bd4-d9993c993ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train loss: 2.7799\n",
            "Epoch 2 | Train loss: 2.3283\n",
            "Epoch 3 | Train loss: 2.1018\n",
            "Epoch 4 | Train loss: 1.9240\n",
            "Epoch 5 | Train loss: 1.7874\n",
            "Epoch 6 | Train loss: 1.7892\n",
            "Epoch 7 | Train loss: 1.6285\n",
            "Epoch 8 | Train loss: 1.4662\n",
            "Epoch 9 | Train loss: 1.2980\n",
            "Epoch 10 | Train loss: 1.2064\n",
            "Epoch 11 | Train loss: 1.1545\n",
            "Epoch 12 | Train loss: 1.0989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def predict_image(model, image, vocab, device, max_len=32):\n",
        "    model.eval()\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32, 100)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    img_tensor = transform(image).unsqueeze(0).to(device)\n",
        "    tgt_input = torch.tensor([[vocab.bos_idx]], dtype=torch.long).to(device)\n",
        "    decoded = []\n",
        "    for _ in range(max_len):\n",
        "        tgt_mask = torch.triu(torch.ones((tgt_input.shape[1], tgt_input.shape[1]), device=device), diagonal=1).bool()\n",
        "        logits = model(img_tensor, tgt_input, tgt_mask)\n",
        "        next_token = logits[:, -1, :].argmax(-1).item()\n",
        "        if next_token == vocab.eos_idx or next_token == vocab.pad_idx:\n",
        "            break\n",
        "        decoded.append(next_token)\n",
        "        tgt_input = torch.cat([tgt_input, torch.tensor([[next_token]], dtype=torch.long).to(device)], dim=1)\n",
        "    return vocab.decode(decoded)\n",
        "\n",
        "img_path = \"/content/IIIT5K/IIIT5K/test/1002_1.png\"  # Đổi đường dẫn ảnh test nếu cần\n",
        "image = Image.open(img_path).convert(\"RGB\")\n",
        "predicted_text = predict_image(model, image, dataset.vocab, device)\n",
        "print(f\"Ảnh: {img_path}\")\n",
        "print(f\"Chuỗi văn bản model sinh ra: {predicted_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv4jK4y4kLrI",
        "outputId": "b8048bdd-90f6-4866-b5a6-ee85f0769915"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ảnh: /content/IIIT5K/IIIT5K/test/1002_1.png\n",
            "Chuỗi văn bản model sinh ra: PRINAT\n"
          ]
        }
      ]
    }
  ]
}