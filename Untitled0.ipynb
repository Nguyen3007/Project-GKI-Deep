{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oLxgpls6PH2i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/vintext.zip\"\n",
        "extract_path = \"/content/vintext\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Đã giải nén VinText.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbwNg4c0TrNU",
        "outputId": "37190020-475e-4d0e-90a7-09810362aa27"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã giải nén VinText.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "LABEL_DIR = '/content/vintext/labels'\n",
        "\n",
        "def collect_characters(label_dir):\n",
        "    charset = set()\n",
        "    for label_file in glob.glob(os.path.join(label_dir, 'gt_*.txt')):\n",
        "        with open(label_file, encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split(',')\n",
        "                if len(parts) < 9:\n",
        "                    continue\n",
        "                text = ','.join(parts[8:]).strip().lower()\n",
        "                if text == '###' or len(text) < 2:\n",
        "                    continue\n",
        "                for ch in text:\n",
        "                    charset.add(ch)\n",
        "    return charset\n",
        "\n",
        "def write_vocab(charset, save_path='/content/vintext/vocab.txt'):\n",
        "    # Thêm các token đặc biệt\n",
        "    tokens = ['<PAD>', '<BOS>', '<EOS>', '<UNK>']\n",
        "    # Sắp xếp charset theo unicode để cố định thứ tự\n",
        "    charset = sorted(list(charset))\n",
        "    with open(save_path, 'w', encoding='utf-8') as f:\n",
        "        for token in tokens:\n",
        "            f.write(token + '\\n')\n",
        "        for ch in charset:\n",
        "            f.write(ch + '\\n')\n",
        "    print(f'Vocab saved to {save_path}. Total chars (not count special tokens): {len(charset)}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    charset = collect_characters(LABEL_DIR)\n",
        "    write_vocab(charset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0Pe1sovVIU8",
        "outputId": "e297c073-017e-483c-e1f5-c1e30d3faa05"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab saved to /content/vintext/vocab.txt. Total chars (not count special tokens): 126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, vocab_path):\n",
        "        self.idx2char = []\n",
        "        with open(vocab_path, encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                self.idx2char.append(line.strip('\\n'))\n",
        "        self.char2idx = {ch: idx for idx, ch in enumerate(self.idx2char)}\n",
        "        self.pad_idx = self.char2idx['<PAD>']\n",
        "        self.bos_idx = self.char2idx['<BOS>']\n",
        "        self.eos_idx = self.char2idx['<EOS>']\n",
        "        self.unk_idx = self.char2idx['<UNK>']\n",
        "\n",
        "    def encode(self, text, max_length):\n",
        "        ids = [self.bos_idx]\n",
        "        for ch in text:\n",
        "            ids.append(self.char2idx.get(ch, self.unk_idx))\n",
        "        ids.append(self.eos_idx)\n",
        "        # Pad to max_length\n",
        "        ids = ids[:max_length]\n",
        "        ids += [self.pad_idx] * (max_length - len(ids))\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids):\n",
        "        chars = []\n",
        "        for idx in ids:\n",
        "            ch = self.idx2char[idx]\n",
        "            if ch in ['<PAD>', '<BOS>', '<EOS>']:\n",
        "                continue\n",
        "            chars.append(ch)\n",
        "        return ''.join(chars)\n",
        "\n",
        "def crop_poly(img, poly):\n",
        "    # poly: [x1, y1, x2, y2, x3, y3, x4, y4]\n",
        "    poly_xy = [(poly[i], poly[i+1]) for i in range(0, 8, 2)]\n",
        "    min_x = max(min([p[0] for p in poly_xy]), 0)\n",
        "    max_x = max([p[0] for p in poly_xy])\n",
        "    min_y = max(min([p[1] for p in poly_xy]), 0)\n",
        "    max_y = max([p[1] for p in poly_xy])\n",
        "    img_crop = img.crop((min_x, min_y, max_x, max_y))\n",
        "    return img_crop\n",
        "\n",
        "class VinTextOCRDataset(Dataset):\n",
        "    def __init__(self, img_dir, label_dir, vocab_path, max_label_length=48, img_height=32, img_width=128, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.vocab = Vocab(vocab_path)\n",
        "        self.max_label_length = max_label_length\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        self.transform = transform or transforms.Compose([\n",
        "            transforms.Resize((img_height, img_width)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        self.samples = []\n",
        "        label_files = sorted(glob.glob(os.path.join(label_dir, \"gt_*.txt\")))\n",
        "        for label_file in label_files:\n",
        "            img_id = os.path.splitext(os.path.basename(label_file))[0][3:]  # gt_1.txt -> '1'\n",
        "            img_name = f\"im{int(img_id):04d}.jpg\"\n",
        "            img_path = os.path.join(img_dir, img_name)\n",
        "            if not os.path.exists(img_path):\n",
        "                continue\n",
        "            with open(label_file, encoding='utf-8') as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split(',')\n",
        "                    if len(parts) < 9:\n",
        "                        continue\n",
        "                    poly = [int(float(x)) for x in parts[:8]]\n",
        "                    text = ','.join(parts[8:]).strip().lower()\n",
        "                    if text == '###' or len(text) < 2:\n",
        "                        continue\n",
        "                    self.samples.append((img_path, poly, text))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, poly, text = self.samples[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img_crop = crop_poly(img, poly)\n",
        "        img_crop = self.transform(img_crop)\n",
        "        label_ids = self.vocab.encode(text, self.max_label_length)\n",
        "        label_ids = torch.tensor(label_ids, dtype=torch.long)\n",
        "        return img_crop, label_ids\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    img_dir = \"/content/vintext/train_images\"\n",
        "    label_dir = \"/content/vintext/labels\"\n",
        "    vocab_path = \"/content/vintext/vocab.txt\"\n",
        "    dataset = VinTextOCRDataset(img_dir, label_dir, vocab_path)\n",
        "    print(\"Samples:\", len(dataset))\n",
        "    img, label_ids = dataset[0]\n",
        "    print(\"Image shape:\", img.shape)\n",
        "    print(\"Label ids:\", label_ids)\n",
        "    print(\"Decoded:\", dataset.vocab.decode(label_ids.tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3BGXNe_g1Zp",
        "outputId": "6a2b0ef1-fb5b-406e-9fcb-841b152e431c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples: 24074\n",
            "Image shape: torch.Size([3, 32, 128])\n",
            "Label ids: tensor([ 1, 39, 44, 88, 56,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
            "Decoded: chất\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNNBackbone(nn.Module):\n",
        "    def __init__(self, out_channels=256):\n",
        "        super().__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, out_channels, 3, padding=1), nn.BatchNorm2d(out_channels), nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        feat = self.conv_layers(x)\n",
        "        return feat"
      ],
      "metadata": {
        "id": "bHMAkvxohHV3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=512):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-torch.log(torch.tensor(10000.0))/d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0)) # (1, max_len, d_model)\n",
        "    def forward(self, x):\n",
        "        # x: (B, seq_len, d_model)\n",
        "        return x + self.pe[:, :x.size(1), :]"
      ],
      "metadata": {
        "id": "5jQC_M1YhVaM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OCRTransformerDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=256, nhead=4, num_layers=3, dropout=0.1, max_len=48):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.token_embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_embed = PositionalEncoding(d_model, max_len)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, d_model*2, dropout)\n",
        "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
        "        self.output_proj = nn.Linear(d_model, vocab_size)\n",
        "    def forward(self, memory, tgt, tgt_mask=None):\n",
        "        tgt_emb = self.token_embed(tgt) * (self.d_model ** 0.5)\n",
        "        tgt_emb = self.pos_embed(tgt_emb)\n",
        "        tgt_emb = tgt_emb.transpose(0,1) # (tgt_len,B,E)\n",
        "        memory = memory.transpose(0,1)\n",
        "        output = self.transformer_decoder(tgt_emb, memory, tgt_mask=tgt_mask)\n",
        "        output = output.transpose(0,1)   # (B, tgt_len, E)\n",
        "        logits = self.output_proj(output)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "R2kajEizhdKV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OCRNet(nn.Module):\n",
        "    def __init__(self, vocab_size, max_seq_len=48, d_model=256):\n",
        "        super().__init__()\n",
        "        self.cnn = CNNBackbone(out_channels=d_model)\n",
        "        self.feat2seq = nn.Linear(d_model, d_model)\n",
        "        self.decoder = OCRTransformerDecoder(vocab_size, d_model, nhead=4, num_layers=3, max_len=max_seq_len)\n",
        "    def forward(self, images, tgt_input, tgt_mask=None):\n",
        "        feat = self.cnn(images)    # (B, C, H', W')\n",
        "        B, C, H, W = feat.shape\n",
        "        feat = feat.permute(0,2,3,1).contiguous().view(B, H*W, C) # (B, src_len, C)\n",
        "        feat = self.feat2seq(feat)\n",
        "        logits = self.decoder(feat, tgt_input, tgt_mask)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "jDP4uFkRhsrL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "vocab_size = 100\n",
        "model = OCRNet(vocab_size=vocab_size, max_seq_len=48).to(device)\n",
        "\n",
        "images = torch.randn(2, 3, 32, 128).to(device)       # Đưa lên device\n",
        "labels_in = torch.randint(0, vocab_size, (2, 48)).to(device)  # Đưa lên device\n",
        "\n",
        "out = model(images, labels_in)\n",
        "print(out.shape)  # kỳ vọng (2, 48, vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X5YKXsvht5L",
        "outputId": "ca4c2ec4-2f52-4949-a0ab-a98d9da272b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 48, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def ocr_loss_fn(logits, labels, pad_idx):\n",
        "    \"\"\"\n",
        "    logits: (B, tgt_len, vocab_size)\n",
        "    labels: (B, tgt_len)\n",
        "    \"\"\"\n",
        "    logits = logits.view(-1, logits.size(-1))\n",
        "    labels = labels.view(-1)\n",
        "    loss = nn.CrossEntropyLoss(ignore_index=pad_idx)(logits, labels)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "QBjCpwvgh_T5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tgt_mask(tgt_input, pad_idx):\n",
        "    # tgt_input: (B, tgt_len)\n",
        "    B, tgt_len = tgt_input.shape\n",
        "    # Mask phía phải (không cho nhìn trước)\n",
        "    tgt_mask = torch.triu(torch.ones((tgt_len, tgt_len)), diagonal=1).bool().to(tgt_input.device)\n",
        "    return tgt_mask  # (tgt_len, tgt_len)"
      ],
      "metadata": {
        "id": "GzBGOSS8h_7e"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, dataloader, optimizer, device, pad_idx):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # Input cho decoder là labels[:, :-1], target là labels[:, 1:]\n",
        "        tgt_input = labels[:, :-1]\n",
        "        tgt_out = labels[:, 1:]\n",
        "        tgt_mask = create_tgt_mask(tgt_input, pad_idx)\n",
        "        logits = model(images, tgt_input, tgt_mask)\n",
        "        loss = ocr_loss_fn(logits, tgt_out, pad_idx)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "1OdPDqSQiBdp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, dataloader, device, pad_idx):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    total_count = 0\n",
        "    for images, labels in dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        tgt_input = labels[:, :-1]\n",
        "        tgt_out = labels[:, 1:]\n",
        "        tgt_mask = create_tgt_mask(tgt_input, pad_idx)\n",
        "        logits = model(images, tgt_input, tgt_mask)\n",
        "        loss = ocr_loss_fn(logits, tgt_out, pad_idx)\n",
        "        total_loss += loss.item()\n",
        "        # Đo char-level accuracy\n",
        "        preds = logits.argmax(dim=-1)\n",
        "        mask = (tgt_out != pad_idx)\n",
        "        acc = ((preds == tgt_out) & mask).sum().item() / mask.sum().item()\n",
        "        total_acc += acc\n",
        "        total_count += 1\n",
        "    return total_loss / total_count, total_acc / total_count"
      ],
      "metadata": {
        "id": "OXaxx1oLiM2O"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Giả sử bạn đã có dataset, vocab, model, pad_idx sẵn\n",
        "pad_idx = dataset.vocab.pad_idx\n",
        "batch_size = 64\n",
        "num_epochs = 5\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Tạo DataLoader (giả sử class VinTextOCRDataset đã được import)\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "# Nếu có tập validation, bạn cũng tạo val_loader tương tự\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_one_epoch(model, train_loader, optimizer, device, pad_idx)\n",
        "    print(f\"Epoch {epoch+1} | Train loss: {train_loss:.4f}\")\n",
        "    # Nếu có val_loader thì thêm đánh giá:\n",
        "    # val_loss, val_acc = evaluate(model, val_loader, device, pad_idx)\n",
        "    # print(f\"Val loss: {val_loss:.4f} | Val acc: {val_acc:.4f}\")\n",
        "\n",
        "# Lưu model\n",
        "torch.save(model.state_dict(), \"/content/ocr_cnn_transformer.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "liucQBFiiNmF",
        "outputId": "17db484b-7d79-4a8c-db8d-15f5804878cd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e71abc9dd3b4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1} | Train loss: {train_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Nếu có val_loader thì thêm đánh giá:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-6ac9c3df7051>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, optimizer, device, pad_idx)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtgt_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtgt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_tgt_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mocr_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-6591b5629252>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, tgt_input, tgt_mask)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, src_len, C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-89d6ec73aa11>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, memory, tgt, tgt_mask)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtgt_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (tgt_len,B,E)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# (B, tgt_len, E)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_seq_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0mtgt_is_causal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_detect_is_causal_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_is_causal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_detect_is_causal_mask\u001b[0;34m(mask, is_causal, size)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_causal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m         causal_comparison = _generate_square_subsequent_mask(\n\u001b[0m\u001b[1;32m   1209\u001b[0m             \u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_generate_square_subsequent_mask\u001b[0;34m(sz, device, dtype)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \"\"\"\n\u001b[1;32m     37\u001b[0m     return torch.triu(\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mdiagonal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    }
  ]
}